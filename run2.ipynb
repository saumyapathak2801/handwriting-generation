{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "# from LSTM import Model\n",
    "# from LSTM import load_pretrained_model\n",
    "import LSTM\n",
    "from LSTM import *\n",
    "from importlib import reload\n",
    "reload(LSTM)\n",
    "from dataloader import DataProcess\n",
    "from sample import *\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_args():\n",
    "    \n",
    "        args = {}\n",
    "        args['rnn_size'] = 100 \n",
    "        args['tsteps'] = 300 \n",
    "        args['batch_size'] = 32 #32 #50 #32\n",
    "        args['num_batches'] = 500 #32 \n",
    "        args['num_mixtures'] = 20\n",
    "        args['learning_rate'] = 0.005\n",
    "        args['alphabet'] = ' abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "        args['tsteps_per_ascii'] = 25\n",
    "        args['epochs'] = 2500 #100\n",
    "        args['biases'] = 1.0\n",
    "        args['logs_dir'] = './logs/'\n",
    "        args['save_path'] = 'saved2/model6/model.ckpt' #'saved2/model.ckpt-3000'\n",
    "        args['load_path'] = 'saved2/model5/model.ckpt'\n",
    "        args['sleep_time'] = 5 #60*5\n",
    "        args['grad_clip'] = 10\n",
    "        args['n_to_save'] = 500\n",
    "        args['scale_factor'] = 20\n",
    "        args['gap'] = 500\n",
    "        args['learning_rate_decay'] = 0.95\n",
    "        args['dropout_prob'] = 0.85\n",
    "        args['train'] = False\n",
    "        args['decay'] = 0.95\n",
    "        args['momentum'] = 0.9\n",
    "        return args\n",
    "\n",
    "def load_pretrained_model(model, path):\n",
    "        global_step = 0\n",
    "        load_was_success = True\n",
    "        try:\n",
    "            save_dir = '/'.join(path.split('/')[:-1])\n",
    "            ckpt = tf.train.get_checkpoint_state(save_dir)\n",
    "            load_path = ckpt.model_checkpoint_path\n",
    "            model.saver.restore(model.sess, load_path)\n",
    "            #load_was_success = True\n",
    "        except Exception as e:\n",
    "#             print(e)\n",
    "            load_was_success = False\n",
    "        else:\n",
    "            model.saver = tf.train.Saver(tf.global_variables())\n",
    "            global_step = int(load_path.split('-')[-1])\n",
    "            load_was_success = True\n",
    "        return load_was_success, global_step\n",
    "    \n",
    "def train_model():\n",
    "    sess = tf.Session()\n",
    "    args = init_args()\n",
    "    args['train'] = True\n",
    "    data_loader = DataProcess(args)\n",
    "    args['num_batches'] = data_loader.num_batches\n",
    "    print(\"num_bacthes\", args['num_batches'])\n",
    "    model = Model(args)\n",
    "    load_was_success, global_step = load_pretrained_model(model, args['save_path'])\n",
    "#     global_step = 0\n",
    "    v_x, v_y = data_loader.get_validation_data()\n",
    "    valid_inputs = {model.input: v_x, model.output: v_y}\n",
    "    plot_loss = []\n",
    "    model.sess.run(tf.assign(model.decay, args['decay']))\n",
    "    model.sess.run(tf.assign(model.momentum, args['momentum']))\n",
    "    for e in range(int(global_step/args['num_batches']), args['epochs']):\n",
    "        model.sess.run(tf.assign(model.learning_rate, args['learning_rate'] * (args['learning_rate_decay'] ** e)))\n",
    "        print(\"Running epoch\", e)\n",
    "        data_loader.init_batch_comp()\n",
    "        c0, c1, c2 = model.istate_cell0.c.eval(), model.istate_cell1.c.eval(), model.istate_cell2.c.eval()\n",
    "        h0, h1, h2 = model.istate_cell0.h.eval(), model.istate_cell1.h.eval(), model.istate_cell2.h.eval()\n",
    "\n",
    "        for b in range(global_step%args['num_batches'], args['num_batches']):\n",
    "            print(b)\n",
    "\n",
    "            i = e * args['num_batches'] + b\n",
    "            if global_step is not 0 : i+=1 ; global_step = 0\n",
    "\n",
    "            if i % args['n_to_save'] == 0 and (i > 0):\n",
    "                model.saver.save(model.sess, args['save_path'], global_step = i) ;\n",
    "\n",
    "            start = time.time()\n",
    "            x, y = data_loader.get_next_batch()\n",
    "            \n",
    "            feed = {model.input: x, model.output: y, \\\n",
    "                    model.istate_cell0.c: c0, model.istate_cell1.c: c1, model.istate_cell2.c: c2, \\\n",
    "                    model.istate_cell0.h: h0, model.istate_cell1.h: h1, model.istate_cell2.h: h2}\n",
    "            [train_loss, _] = model.sess.run([model.cost, model.train_op], feed)\n",
    "\n",
    "            end = time.time()\n",
    "            print(\"train_loss: \" + str(i))\n",
    "            print(train_loss)\n",
    "            plot_loss.append(train_loss)\n",
    "#             if i % 10 is 0:\n",
    "#                 print(\"train_loss: \" + str(i))\n",
    "#                 print(train_loss)\n",
    "#                 plot_loss.append(train_loss)\n",
    "    plt.plot(plot_loss, linewidth=2.0)\n",
    "    plt.savefig(\"./loss.png\")\n",
    "\n",
    "def sample_model():\n",
    "    args = init_args()\n",
    "    args['tsteps'] = 1\n",
    "    args['batch_size'] = 1\n",
    "#     if args['text'] == '':\n",
    "#     strings = ['Machine generated handwriting'] # test strings\n",
    "#     else:\n",
    "#         strings = [args['text']]\n",
    "\n",
    "    model = Model(args)\n",
    "\n",
    "    load_was_success, global_step = load_pretrained_model(model, args['load_path'])\n",
    "    print(global_step)\n",
    "    s = \"hello world\"\n",
    "    if load_was_success:\n",
    "            strokes, char_to_plot = sample(model, args)\n",
    "            l_save_path = '{}figures/iter-{}-l-{}'.format(args['logs_dir'], global_step, s[:10].replace(' ', '_'))\n",
    "\n",
    "            gauss_plot(strokes, 'Heatmap for \"{}\"'.format(s), figsize = (2*len(s),4), save_path=\"./gauss5.png\")\n",
    "#             line_plot(strokes, 'Line plot for \"{}\"'.format(s), figsize = (len(s),2), save_path=\"./line5.png\")\n",
    "            line_plot(strokes, 'Line plot for \"{}\"'.format(s), figsize = (len(s),2), save_path=l_save_path)\n",
    "            line_plot3(strokes, char_to_plot, 'Line plot for \"{}\"'.format(s), figsize = (len(s),2), save_path=\"./line_char5.png\")\n",
    "#             line_plot2(char_to_plot, 'Line plot for \"{}\"'.format(s), figsize = (len(s),2), save_path=\"./line_char6.png\")\n",
    "            print(\"plotted\")\n",
    "\n",
    "    else:\n",
    "        print(\"load failed, sampling canceled\")\n",
    "\n",
    "#     if True:\n",
    "#         print(\"calling sample again\")\n",
    "#         tf.reset_default_graph()\n",
    "#         time.sleep(args['sleep_time'])\n",
    "#         sample_model()\n",
    "        \n",
    "# def sample_new():\n",
    "#     i = 0\n",
    "#     while(i < 5):\n",
    "#         sample_model()\n",
    "#         i++\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved {} lines 226\n",
      "Number of data examples: 202\n",
      "Batch size for dataset 6\n",
      "num_bacthes 6\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/saumyap/writing-synthesis/LSTM.py:45: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/saumyap/writing-synthesis/mdn2.py:32: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /Users/saumyap/writing-synthesis/mdn2.py:43: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from saved2/model6/model.ckpt-1500\n",
      "Running epoch 250\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
