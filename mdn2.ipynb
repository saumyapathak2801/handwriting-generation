{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now transform dense NN outputs into params for MDN\n",
    "def get_mdn_coef(model, Z):\n",
    "    # returns the tf slices containing mdn dist params (eq 18...23 of http://arxiv.org/abs/1308.0850)\n",
    "    eos_hat = Z[:, 0:1] #end of sentence tokens\n",
    "    pi_hat, mu1_hat, mu2_hat, sigma1_hat, sigma2_hat, rho_hat = tf.split(Z[:, 1:], 6, 1)\n",
    "    model.pi_hat, model.sigma1_hat, model.sigma2_hat = pi_hat, sigma1_hat, sigma2_hat \n",
    "\n",
    "    eos = tf.sigmoid(-1*eos_hat) # technically we gained a negative sign\n",
    "    pi = tf.nn.softmax(pi_hat) # softmax z_pi:\n",
    "    mu1 = mu1_hat; mu2 = mu2_hat # leave mu1, mu2 as they are\n",
    "    sigma1 = tf.exp(sigma1_hat); sigma2 = tf.exp(sigma2_hat) # exp for sigmas\n",
    "    rho = tf.tanh(rho_hat) # tanh for rho (squish between -1 and 1)rrr\n",
    "\n",
    "    return [eos, pi, mu1, mu2, sigma1, sigma2, rho]\n",
    "\n",
    "def gaussian2d(x1, x2, mu1, mu2, s1, s2, rho):\n",
    "            # define gaussian mdn (eq 24, 25 from http://arxiv.org/abs/1308.0850)\n",
    "    x_mu1 = tf.subtract(x1, mu1)\n",
    "    x_mu2 = tf.subtract(x2, mu2)\n",
    "    Z = tf.square(tf.div(x_mu1, s1)) + tf.square(tf.div(x_mu2, s2)) - 2*tf.div(tf.multiply(rho, tf.multiply(x_mu1, x_mu2)), tf.multiply(s1, s2))\n",
    "    rho_square_term = 1-tf.square(rho)\n",
    "    power_e = tf.exp(tf.div(-Z,2*rho_square_term))\n",
    "    regularize_term = 2*np.pi*tf.multiply(tf.multiply(s1, s2), tf.sqrt(rho_square_term))\n",
    "    gaussian = tf.div(power_e, regularize_term)\n",
    "    return gaussian\n",
    "\n",
    "def get_loss(pi, x1_data, x2_data, eos_data, mu1, mu2, sigma1, sigma2, rho, eos):\n",
    "    # define loss function (eq 26 of http://arxiv.org/abs/1308.0850)\n",
    "    gaussian = gaussian2d(x1_data, x2_data, mu1, mu2, sigma1, sigma2, rho)\n",
    "    term1 = tf.multiply(gaussian, pi)\n",
    "    term1 = tf.reduce_sum(term1, 1, keep_dims=True) #do inner summation\n",
    "    term1 = -tf.log(tf.maximum(term1, 1e-20)) # some errors are zero -> numerical errors.\n",
    "\n",
    "    term2 = tf.multiply(eos, eos_data) + tf.multiply(1-eos, 1-eos_data) #modified Bernoulli -> eos probability\n",
    "    term2 = -tf.log(term2) #negative log error gives loss\n",
    "\n",
    "    return tf.reduce_sum(term1 + term2) #do outer summation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
